<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.4 Exercises | Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction</title>
  <meta name="description" content="Linear Mixed Models for Linguistics and Psychology: A Comprehensive Introduction" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="2.4 Exercises | Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://bookdown.org/yihui/bookdown/" />
  <meta property="og:image" content="https://bookdown.org/yihui/bookdown/images/cover.jpg" />
  <meta property="og:description" content="Linear Mixed Models for Linguistics and Psychology: A Comprehensive Introduction" />
  <meta name="github-repo" content="rstudio/bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.4 Exercises | Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction" />
  
  <meta name="twitter:description" content="Linear Mixed Models for Linguistics and Psychology: A Comprehensive Introduction" />
  <meta name="twitter:image" content="https://bookdown.org/yihui/bookdown/images/cover.jpg" />

<meta name="author" content="Shravan Vasishth, Daniel Schad, Audrey BÃ¼rki, Reinhold Kliegl" />


<meta name="date" content="2020-07-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="further-reading-1.html"/>
<link rel="next" href="important-distributions.html"/>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Authoring Books with R Markdown</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>0.1</b> Prerequisites</a></li>
<li class="chapter" data-level="0.2" data-path="how-to-read-this-book.html"><a href="how-to-read-this-book.html"><i class="fa fa-check"></i><b>0.2</b> How to read this book</a></li>
<li class="chapter" data-level="0.3" data-path="online-materials.html"><a href="online-materials.html"><i class="fa fa-check"></i><b>0.3</b> Online materials</a></li>
<li class="chapter" data-level="0.4" data-path="software-needed.html"><a href="software-needed.html"><i class="fa fa-check"></i><b>0.4</b> Software needed</a></li>
<li class="chapter" data-level="0.5" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>0.5</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introprob.html"><a href="introprob.html"><i class="fa fa-check"></i><b>1.1</b> Probability</a></li>
<li class="chapter" data-level="1.2" data-path="conditional-probability.html"><a href="conditional-probability.html"><i class="fa fa-check"></i><b>1.2</b> Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="discrete-random-variables-an-example-using-the-binomial-distribution.html"><a href="discrete-random-variables-an-example-using-the-binomial-distribution.html"><i class="fa fa-check"></i><b>1.3</b> Discrete random variables: An example using the Binomial distribution</a><ul>
<li class="chapter" data-level="1.3.1" data-path="discrete-random-variables-an-example-using-the-binomial-distribution.html"><a href="discrete-random-variables-an-example-using-the-binomial-distribution.html#the-mean-and-variance-of-the-binomial-distribution"><i class="fa fa-check"></i><b>1.3.1</b> The mean and variance of the Binomial distribution</a></li>
<li class="chapter" data-level="1.3.2" data-path="discrete-random-variables-an-example-using-the-binomial-distribution.html"><a href="discrete-random-variables-an-example-using-the-binomial-distribution.html#what-information-does-a-probability-distribution-provide"><i class="fa fa-check"></i><b>1.3.2</b> What information does a probability distribution provide?</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="continuous-random-variables-an-example-using-the-normal-distribution.html"><a href="continuous-random-variables-an-example-using-the-normal-distribution.html"><i class="fa fa-check"></i><b>1.4</b> Continuous random variables: An example using the Normal distribution</a></li>
<li class="chapter" data-level="1.5" data-path="an-important-concept-the-marginal-likelihood-integrating-out-a-parameter.html"><a href="an-important-concept-the-marginal-likelihood-integrating-out-a-parameter.html"><i class="fa fa-check"></i><b>1.5</b> An important concept: The marginal likelihood (integrating out a parameter)</a></li>
<li class="chapter" data-level="1.6" data-path="summary-of-useful-r-functions-relating-to-distributions.html"><a href="summary-of-useful-r-functions-relating-to-distributions.html"><i class="fa fa-check"></i><b>1.6</b> Summary of useful R functions relating to distributions</a></li>
<li class="chapter" data-level="1.7" data-path="summary-of-random-variable-theory.html"><a href="summary-of-random-variable-theory.html"><i class="fa fa-check"></i><b>1.7</b> *Summary of random variable theory</a></li>
<li class="chapter" data-level="1.8" data-path="summary-of-concepts-introduced-in-this-chapter.html"><a href="summary-of-concepts-introduced-in-this-chapter.html"><i class="fa fa-check"></i><b>1.8</b> Summary of concepts introduced in this chapter</a></li>
<li class="chapter" data-level="1.9" data-path="further-reading.html"><a href="further-reading.html"><i class="fa fa-check"></i><b>1.9</b> Further reading</a></li>
<li class="chapter" data-level="1.10" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.10</b> Exercises</a><ul>
<li class="chapter" data-level="1.10.1" data-path="exercises.html"><a href="exercises.html#practice-using-the-pnorm-function"><i class="fa fa-check"></i><b>1.10.1</b> Practice using the <code>pnorm</code> function</a></li>
<li class="chapter" data-level="1.10.2" data-path="exercises.html"><a href="exercises.html#practice-using-the-qnorm-function"><i class="fa fa-check"></i><b>1.10.2</b> Practice using the <code>qnorm</code> function</a></li>
<li class="chapter" data-level="1.10.3" data-path="exercises.html"><a href="exercises.html#practice-using-qt"><i class="fa fa-check"></i><b>1.10.3</b> Practice using <code>qt</code></a></li>
<li class="chapter" data-level="1.10.4" data-path="exercises.html"><a href="exercises.html#maximum-likelihood-estimation-1"><i class="fa fa-check"></i><b>1.10.4</b> Maximum likelihood estimation 1</a></li>
<li class="chapter" data-level="1.10.5" data-path="exercises.html"><a href="exercises.html#maximum-likelihood-estimation-2"><i class="fa fa-check"></i><b>1.10.5</b> Maximum likelihood estimation 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introBDA.html"><a href="introBDA.html"><i class="fa fa-check"></i><b>2</b> Introduction to Bayesian data analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="sec-analytical.html"><a href="sec-analytical.html"><i class="fa fa-check"></i><b>2.1</b> Deriving the posterior using Bayesâ rule: An analytical example</a><ul>
<li class="chapter" data-level="2.1.1" data-path="sec-analytical.html"><a href="sec-analytical.html#choosing-a-likelihood"><i class="fa fa-check"></i><b>2.1.1</b> Choosing a likelihood</a></li>
<li class="chapter" data-level="2.1.2" data-path="sec-analytical.html"><a href="sec-analytical.html#choosing-a-prior-for-theta"><i class="fa fa-check"></i><b>2.1.2</b> Choosing a prior for <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="2.1.3" data-path="sec-analytical.html"><a href="sec-analytical.html#using-bayes-rule-to-compute-the-posterior-pthetank"><i class="fa fa-check"></i><b>2.1.3</b> Using Bayesâ rule to compute the posterior <span class="math inline">\(p(\theta|n,k)\)</span></a></li>
<li class="chapter" data-level="2.1.4" data-path="sec-analytical.html"><a href="sec-analytical.html#summary-of-the-procedure"><i class="fa fa-check"></i><b>2.1.4</b> Summary of the procedure</a></li>
<li class="chapter" data-level="2.1.5" data-path="sec-analytical.html"><a href="sec-analytical.html#visualizing-the-prior-likelihood-and-the-posterior"><i class="fa fa-check"></i><b>2.1.5</b> Visualizing the prior, likelihood, and the posterior</a></li>
<li class="chapter" data-level="2.1.6" data-path="sec-analytical.html"><a href="sec-analytical.html#the-posterior-distribution-is-a-compromise-between-the-prior-and-the-likelihood"><i class="fa fa-check"></i><b>2.1.6</b> The posterior distribution is a compromise between the prior and the likelihood</a></li>
<li class="chapter" data-level="2.1.7" data-path="sec-analytical.html"><a href="sec-analytical.html#incremental-knowledge-gain-using-prior-knowledge"><i class="fa fa-check"></i><b>2.1.7</b> Incremental knowledge gain using prior knowledge</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="summary-of-concepts-introduced-in-this-chapter-1.html"><a href="summary-of-concepts-introduced-in-this-chapter-1.html"><i class="fa fa-check"></i><b>2.2</b> Summary of concepts introduced in this chapter</a></li>
<li class="chapter" data-level="2.3" data-path="further-reading-1.html"><a href="further-reading-1.html"><i class="fa fa-check"></i><b>2.3</b> Further reading</a></li>
<li class="chapter" data-level="2.4" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>2.4</b> Exercises</a><ul>
<li class="chapter" data-level="2.4.1" data-path="exercises-1.html"><a href="exercises-1.html#deriving-bayes-rule"><i class="fa fa-check"></i><b>2.4.1</b> Deriving Bayesâ rule</a></li>
<li class="chapter" data-level="2.4.2" data-path="exercises-1.html"><a href="exercises-1.html#conjugate-forms-1"><i class="fa fa-check"></i><b>2.4.2</b> Conjugate forms 1</a></li>
<li class="chapter" data-level="2.4.3" data-path="exercises-1.html"><a href="exercises-1.html#conjugate-forms-2"><i class="fa fa-check"></i><b>2.4.3</b> Conjugate forms 2</a></li>
<li class="chapter" data-level="2.4.4" data-path="exercises-1.html"><a href="exercises-1.html#conjugate-forms-3"><i class="fa fa-check"></i><b>2.4.4</b> Conjugate forms 3</a></li>
<li class="chapter" data-level="2.4.5" data-path="exercises-1.html"><a href="exercises-1.html#conjugate-forms-4"><i class="fa fa-check"></i><b>2.4.5</b> Conjugate forms 4</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="important-distributions.html"><a href="important-distributions.html"><i class="fa fa-check"></i><b>3</b> Important distributions</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="exercises-1" class="section level2">
<h2><span class="header-section-number">2.4</span> Exercises</h2>
<div id="deriving-bayes-rule" class="section level3">
<h3><span class="header-section-number">2.4.1</span> Deriving Bayesâ rule</h3>
<p>Let A and B be two observable events. P(A) is the probability that A occurs, and P(B) is the probability that B occurs. <span class="math inline">\(P(A|B)\)</span> is the conditional probability that A occurs given that B has happened. <span class="math inline">\(P(A,B)\)</span> is the joint probability of A and B both occurring.</p>
<p>You are given the definition of conditional probability:</p>
<p><span class="math display">\[\begin{equation}
P(A|B)= \frac{P(A,B)}{P(B)} \hbox{ where } P(B)&gt;0
\end{equation}\]</span></p>
<p>Using the above definition, and using the fact that <span class="math inline">\(P(A,B)=P(B,A)\)</span> (i.e., the probability of A and B both occurring is the same as the probability of B and A both occurring),
derive an expression for <span class="math inline">\(P(B|A)\)</span>. Show the steps clearly in the derivation.</p>
</div>
<div id="conjugate-forms-1" class="section level3">
<h3><span class="header-section-number">2.4.2</span> Conjugate forms 1</h3>
<div id="computing-the-general-form-of-a-pdf-for-a-posterior" class="section level4">
<h4><span class="header-section-number">2.4.2.1</span> Computing the general form of a PDF for a posterior</h4>
<p>Suppose you are given a vector of data <span class="math inline">\(x\)</span> consisting of 1âs and 0âs, coming from a Binomial(n,<span class="math inline">\(\theta\)</span>) distribution. 1 represents success, and 0 failure. Example data are shown below, generated with probability of success <span class="math inline">\(\theta=0.5\)</span>, just for illustration:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb57-1" data-line-number="1"><span class="co">## data:</span></a>
<a class="sourceLine" id="cb57-2" data-line-number="2">x&lt;-<span class="kw">rbinom</span>(<span class="dt">n=</span><span class="dv">10</span>,<span class="dt">size=</span><span class="dv">1</span>,<span class="dt">prob=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb57-3" data-line-number="3">x</a></code></pre></div>
<pre><code>##  [1] 1 1 1 0 0 1 1 0 1 0</code></pre>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb59-1" data-line-number="1"><span class="co">## k:</span></a>
<a class="sourceLine" id="cb59-2" data-line-number="2"><span class="kw">sum</span>(x)</a></code></pre></div>
<pre><code>## [1] 6</code></pre>
<p>Here, n represents the number of trials, and k the number of successes. The above code and output is just an example, and is no longer relevant for the question below.</p>
<p>Given k successes in n trials coming from a Binomial distribution, we define a Beta(a,b) prior on the parameter <span class="math inline">\(\theta\)</span>.</p>
<p>Write down the Beta distribution that represents the posterior, in terms of a,b, n, and k.</p>
</div>
<div id="practical-application" class="section level4">
<h4><span class="header-section-number">2.4.2.2</span> Practical application</h4>
<p>We ask 10 yes/no questions from a participant, and the participant returns 0 correct answers. We assume a Binomial likelihood function for these data. Also assume a Beta(1,1) prior on the parameter <span class="math inline">\(\theta\)</span>, which represents the probability of success. Use the result you derived above to write down the posterior distribution of the <span class="math inline">\(\theta\)</span> parameter.</p>
</div>
</div>
<div id="conjugate-forms-2" class="section level3">
<h3><span class="header-section-number">2.4.3</span> Conjugate forms 2</h3>
<p>Suppose you have <span class="math inline">\(n\)</span> independent and identically distributed data points from a distribution that has
the likelihood function <span class="math inline">\(f(x|\theta)=\theta(1-\theta)^{\sum_{i=1}^n x_i}\)</span>,
where the data points <span class="math inline">\(x\)</span> can have values 0,1,2,. Let the prior on <span class="math inline">\(\theta\)</span> be Beta(a,b), a Beta distribution with parameters a,b.
The posterior distribution is a Beta distribution with parameters a* and b*.
Determine these parameters in terms of <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and <span class="math inline">\(\sum_{i=1}^n x_i\)</span>.</p>
</div>
<div id="conjugate-forms-3" class="section level3">
<h3><span class="header-section-number">2.4.4</span> Conjugate forms 3</h3>
<p>The Gamma distribution is defined in terms of the parameters a, b: Ga(a,b). The probability density function is:</p>
<p><span class="math display">\[\begin{equation}
Ga(a,b)=\frac{b^a \lambda^{a-1} \exp\{-b\lambda\}}{\Gamma(a)}
\end{equation}\]</span></p>
<p>We have data <span class="math inline">\(x_1,\dots, x_n\)</span>, with sample size <span class="math inline">\(n\)</span> that is exponentially distributed. The exponential likelihood function is:</p>
<p><span class="math display">\[\begin{equation}
p(x_1,\dots,x_n | \lambda)=\lambda^n \exp \{-\lambda \sum_{i=1}^n x_i \}
\end{equation}\]</span></p>
<p>It turns out that if we assume a Ga(a,b) prior distribution and the above likelihood, the posterior distribution is a Gamma distribution. Find the parameters <span class="math inline">\(a&#39;\)</span> and <span class="math inline">\(b&#39;\)</span> of the posterior distribution.</p>
</div>
<div id="conjugate-forms-4" class="section level3">
<h3><span class="header-section-number">2.4.5</span> Conjugate forms 4</h3>
<div id="a.-computing-the-posterior" class="section level4">
<h4><span class="header-section-number">2.4.5.1</span> a. Computing the posterior</h4>
<p>This is a contrived example. Suppose we are modeling the number of times that a speaker says the word âIâ per day. This could be of interest if we are studying, for example, how self-oriented a speaker is. The number of times <span class="math inline">\(x\)</span> that the word is uttered in over a oarticular time period (here, one day) can be modeled by a Poisson distribution:</p>
<p><span class="math display">\[\begin{equation}
f(x\mid \theta) = \frac{\exp(-\theta) \theta^x}{x!}
\end{equation}\]</span></p>
<p>where the rate <span class="math inline">\(\theta\)</span> is unknown, and the numbers of utterances of the target word on each day are independent given <span class="math inline">\(\theta\)</span>.</p>
<p>We are told that the prior mean of <span class="math inline">\(\theta\)</span> is 100 and prior variance for <span class="math inline">\(\theta\)</span> is 225. This information is based on the results of previous studies on the topic. We will use the Gamma(a,b) density (see previous question) as a prior for <span class="math inline">\(\theta\)</span> because this is a conjugate prior to the Poisson distribution.</p>
<ul>
<li>First, visualize the prior. a Gamma density prior for <span class="math inline">\(\theta\)</span> based on the above information.</li>
</ul>
<p>[Hint: Note that we know that for a Gamma density with parameters a, b, the mean is <span class="math inline">\(\frac{a}{b}\)</span> and the variance is <span class="math inline">\(\frac{a}{b^2}\)</span>. Since we are given values for the mean and variance, we can solve for a,b, which gives us the Gamma density.]</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb61-1" data-line-number="1">x&lt;-<span class="dv">0</span><span class="op">:</span><span class="dv">200</span></a>
<a class="sourceLine" id="cb61-2" data-line-number="2"><span class="kw">plot</span>(x,<span class="kw">dgamma</span>(x,<span class="dv">10000</span><span class="op">/</span><span class="dv">225</span>,<span class="dv">100</span><span class="op">/</span><span class="dv">225</span>),<span class="dt">type=</span><span class="st">&quot;l&quot;</span>,<span class="dt">lty=</span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb61-3" data-line-number="3">     <span class="dt">main=</span><span class="st">&quot;Gamma prior&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;density&quot;</span>,</a>
<a class="sourceLine" id="cb61-4" data-line-number="4">     <span class="dt">cex.lab=</span><span class="dv">2</span>,<span class="dt">cex.main=</span><span class="dv">2</span>,<span class="dt">cex.axis=</span><span class="dv">2</span>)</a></code></pre></div>
<ul>
<li>Next, derive the posterior distribution of the parameter <span class="math inline">\(\theta\)</span> up to proportionality, and write down the posterior distribution in terms of the parameters of a Gamma distribution.</li>
</ul>
<!--This means that $a^{*}=a+\sum_i^{n} x_i$ and $b^{*}=b+n$.
We can find a constant $k$ such that the above is a proper probability density function, i.e.:

\begin{equation}
\int_{-\infty}^{\infty} k \theta^{a^{*}-1} \exp(-\theta b^{*})=1
\end{equation}

Thus, the posterior has the form of  a Gamma distribution with parameters 
$a^{*}=a+\sum_i^{n} x_i, b^{*}=b+n$. Hence the Gamma distribution is a conjugate prior for the Poisson.
-->
</div>
<div id="b.-practical-application" class="section level4">
<h4><span class="header-section-number">2.4.5.2</span> b. Practical application</h4>
<p>Suppose we know that the number of âIâ utterances from a particular individual is <span class="math inline">\(115, 97, 79, 131\)</span>. Use the result you derived above to obtain the posterior distribution. In other words, write down the a,b parameters of the Gamma distribution representing the posterior distribution of <span class="math inline">\(\theta\)</span>.</p>
<!--
The prior is Gamma(a=10000/225,b=100/225). The data are as given; this means that $\sum_i^{n} x_i = 422$ and sample size $n=4$.
It follows that the posterior is 

\begin{equation}
\begin{split}
Gamma(a^{*}= a+\sum_i^{n} x_i, b^{*}=b+n) =& 
Gamma(10000/225+422,4+100/225)\\
=& Gamma(466.44,4.44)\\
\end{split}
\end{equation}

The mean and variance of this distribution can be computed using the fact that the mean is $\frac{a*}{b*}=466.44/4.44=104.95$ and the variance is $\frac{a*}{b*^{2}}=466.44/4.44^2=23.66$.



```r
### load data:
data<-c(115,97,79,131)

a.star<-function(a,data){
  return(a+sum(data))
}

b.star<-function(b,n){
  return(b+n)
}

new.a<-a.star(10000/225,data)
new.b<-b.star(100/225,length(data))

### post. mean
(post.mean<-new.a/new.b) 
```

```
## [1] 105
```

```r
### post. var:
(post.var<-new.a/(new.b^2)) 
```

```
## [1] 23.61
```
-->
<p>Plot the prior, likelihood, and the posterior alongside each other.</p>
<p>Now suppose you get one new data point: 200. Write down the updated posterior (the a,b parameters of the Gamma distribution) given this new data-point. Add the updated posterior to the plot you made above.</p>
<!--


```r
new.data<-c(200)
```

We can compute the parameters of the posterior Gamma distributions using the function we wrote above:


```r
new.a.2<-a.star(new.a,new.data)
new.b.2<-b.star(new.b,length(new.data))

### new mean
(new.post.mean<-new.a.2/new.b.2)
```

```
## [1] 122.4
```

```r
### new var:
(new.post.var<-new.a.2/(new.b.2^2))
```

```
## [1] 22.48
```

Thus, new data can be used with the previous posterior distribution as prior, to compute the new posterior.
-->

</div>
</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="further-reading-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="important-distributions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown/edit/master/inst/examples/02-introBDA.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown.pdf", "bookdown.epub", "bookdown.mobi"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
